{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font color=black>\n",
    "\n",
    "**What?** Code profiling\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing your code\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- `%timeit`: times only the line and runs the line it many times and gives more statistics.\n",
    "- `%%timeit`: times the whole cell and runs the it many times and gives more statistics.\n",
    "\n",
    "    \n",
    "- `%time` and `%%time` times it but extecuted it only **once**.\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.58 µs ± 447 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1000 \n",
    "l = [k for k in range(10**2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.89 µs ± 432 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "3.84 µs ± 122 ns per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1000 l = [k for k in range(10**2)]\n",
    "\n",
    "%timeit -n10 l = [k for k in range(10**2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This would not work!\n",
    "%timeit -n1000 \n",
    "l = [k for k in range(10**2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 µs, sys: 1 µs, total: 13 µs\n",
      "Wall time: 16 µs\n"
     ]
    }
   ],
   "source": [
    "%time l = [k for k in range(10**2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.36 µs ± 166 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Saving the output\n",
    "o = %timeit -o l = [k for k in range(10**2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.36 µs ± 166 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- Setting the number of runs `-r` and/or loops `-n`\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 22.63 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "132 µs ± 121 µs per loop (mean ± std. dev. of 2 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Set number of runs to 2 (-r2) \n",
    "# Set number of loops to 10 (-n10) \n",
    "import numpy as np\n",
    "%timeit -r2 -n10 rand_nums = np.random.rand(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 8.26 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "25.1 µs ± 23.6 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "times = %timeit -r10 -n10 -o rand_nums = np.random.rand(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.534489999794005e-05,\n",
       " 1.7086199997606853e-05,\n",
       " 2.082629999904384e-05,\n",
       " 2.081569999745625e-05,\n",
       " 1.7007799999646523e-05,\n",
       " 1.726350000126331e-05,\n",
       " 2.02384999994365e-05,\n",
       " 1.8249600000785903e-05,\n",
       " 1.2852799997631337e-05,\n",
       " 1.1537899999325418e-05]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times.timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1537899999325418e-05\n",
      "9.534489999794005e-05\n"
     ]
    }
   ],
   "source": [
    "print(times.best)\n",
    "print(times.worst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile your code\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- `%prun`  = Run code with the profiler\n",
    "- `%lprun` = Run code with the line-by-line profiler\n",
    "- `%memit` = Measure the memory use of a single statement\n",
    "- `%mprun` = Run code with the line-by-line memory profiler\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_lists(N):\n",
    "    total = 0\n",
    "    for i in range(5):\n",
    "        L = [j ^ (j >> i) for j in range(N)]\n",
    "        total += sum(L)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          14 function calls in 0.747 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        5    0.658    0.132    0.658    0.132 <ipython-input-8-e6935120a5e0>:4(<listcomp>)\n",
      "        5    0.041    0.008    0.041    0.008 {built-in method builtins.sum}\n",
      "        1    0.036    0.036    0.735    0.735 <ipython-input-8-e6935120a5e0>:1(sum_of_lists)\n",
      "        1    0.012    0.012    0.747    0.747 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.747    0.747 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to access the output on the output cell rather than a popup window\n",
    "# https://github.com/ipython/ipython/issues/2091/\n",
    "p = %prun - r sum_of_lists(1000000)\n",
    "p.stream = sys.stdout\n",
    "p.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.00784 s\n",
      "File: <ipython-input-8-e6935120a5e0>\n",
      "Function: sum_of_lists at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def sum_of_lists(N): \n",
      "     2         1          5.0      5.0      0.1      total = 0\n",
      "     3         6          7.0      1.2      0.1      for i in range(5): \n",
      "     4         5       7654.0   1530.8     97.6              L=[j^(j>>i) for j in range(N)] \n",
      "     5         5        174.0     34.8      2.2              total += sum(L)\n",
      "     6         1          0.0      0.0      0.0      return total\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = %lprun - rf sum_of_lists sum_of_lists(5000)\n",
    "p.stream = sys.stdout\n",
    "p.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 53.88 MiB, increment: 0.29 MiB\n"
     ]
    }
   ],
   "source": [
    "p = %memit sum_of_lists(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- To be able to use `mprun` magic command, we have to store the function locally.\n",
    "- This is done automatically my writing `%%file sum_of_lists.py` which saves a local file\n",
    "called `file sum_of_lists.py`\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code profiling.ipynb\r\n",
      "Coding interview cheat-sheet.ipynb\r\n",
      "Fibonacci.ipynb\r\n",
      "Prime numbers.ipynb\r\n",
      "Questions around ARRAY manipulation.ipynb\r\n",
      "Questions around STRING manipulation.ipynb\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m\r\n",
      "sum_of_lists.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# This command -> %%file will write a local file on disk\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# This command -> %%file will write a local file on disk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sum_of_lists.py\n"
     ]
    }
   ],
   "source": [
    "%%file sum_of_lists.py\n",
    "def sum_of_lists(N): \n",
    "    total = 0\n",
    "    for i in range(5): \n",
    "            L=[j^(j>>i) for j in range(N)] \n",
    "            total += sum(L)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# You now have to import the function explcitly\n",
    "from sum_of_lists import sum_of_lists\n",
    "m = %mprun -rf sum_of_lists sum_of_lists(5000)\n",
    "m.stream = sys.stdout\n",
    "m\n",
    "# We'll delete the file as it is not needed!\n",
    "!rm sum_of_lists.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_count_ctxmgr',\n",
       " '_original_trace_function',\n",
       " 'add_function',\n",
       " 'backend',\n",
       " 'code_map',\n",
       " 'disable',\n",
       " 'disable_by_count',\n",
       " 'enable',\n",
       " 'enable_by_count',\n",
       " 'enable_count',\n",
       " 'max_mem',\n",
       " 'prev_lineno',\n",
       " 'prevlines',\n",
       " 'runctx',\n",
       " 'stream',\n",
       " 'trace_max_mem',\n",
       " 'trace_memory_usage',\n",
       " 'wrap_function']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "m does not have a print_stats()\n",
    "so at the moment I do not know how I would pull that data!\n",
    "\"\"\"\n",
    "dir(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
