{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**What?** scoop\n",
    "\n",
    "**Reference:** https://github.com/chryswoods/siremol.org/blob/master/chryswoods.com/parallel_python/mapreduce_part3.md<br>\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running scoop on your single local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- You must ensure that all use of Scoop is protected within an if __name__ == \"__main__\" block.\n",
    "- You must import all modules and declare all functions at the top of your script, before the if __name__ == \"__main__\" block.\n",
    "- Create a new script called **mapreduce.py** and type into it\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoop import futures\n",
    "\n",
    "def product(x, y):\n",
    "    \"\"\"Return the product of the arguments\"\"\"\n",
    "    return x*y\n",
    "\n",
    "def sum(x, y):\n",
    "    \"\"\"Return the sum of the arguments\"\"\"\n",
    "    return x+y\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    a = range(1,101)\n",
    "    b = range(101, 201)\n",
    "\n",
    "    results = futures.map(product, a, b)\n",
    "\n",
    "    total = reduce(sum, results)\n",
    "\n",
    "    print(\"Sum of the products equals %d\" % total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Run this script using the command\n",
    "- python -m scoop mapreduce.py \n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scoop.futures.mapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- In the above example, we used scoop.futures.map to map the sum function. \n",
    "- All of the results were then transmitted back to the master process to complete the reduction (sum). \n",
    "- This is inefficient, as it means that a lot of data needs to be transmitted back to the master. \n",
    "- A better approach is to allow all of the workers in the cluster to perform the reduction as a group, thereby minimising communication.\n",
    "- This can be achieved by using the scoop.futures.mapReduce function. \n",
    "- This combines the map and reduce into a single function call.  \n",
    "- Create a new script called **mapreduce_1.py**\n",
    "- Run the script using **python -m scoop mapreduce.py**\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoop import futures\n",
    "\n",
    "def product(x, y):\n",
    "    \"\"\"Return the product of the arguments\"\"\"\n",
    "    return x*y\n",
    "\n",
    "def sum(x, y):\n",
    "    \"\"\"Return the sum of the arguments\"\"\"\n",
    "    return x+y\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    a = range(1,101)\n",
    "    b = range(101, 201)\n",
    "\n",
    "    total = futures.mapReduce(product, sum, a, b)\n",
    "\n",
    "    print(\"Sum of the products equals %d\" % total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Scoop on a Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Scoop uses **SSH** to connect to and communicate between computers in a cluster.  \n",
    "- You specify which computers to use for your job using a host file which contains a list of hostnames \n",
    "- run **python -m scoop --hostfile hostfile script.py**\n",
    "- Scoop comes with in-built support for many cluster schedulers, e.g. Sun Grid Engine (SGE), Torque (PBS-compatible, Moab, Maui) and SLURM.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
