{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font color=black>\n",
    "\n",
    "**What?** Multiprocessing\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<font color=black><br>\n",
    "\n",
    "- If you have forty cores available, then your script should ideally be able to do forty things at once.\n",
    "- However my Apple machines says:\n",
    "    \n",
    "Hardware Overview:<br>\n",
    "\n",
    "Model Name:\tMacBook Pro<br>\n",
    "Model Identifier:\tMacBookPro13,3<br>\n",
    "Processor Name:\tIntel Core i7<br>\n",
    "Processor Speed:\t2.6 GHz<br>\n",
    "Number of Processors:\t1<br>\n",
    "Total Number of Cores:\t4<br>\n",
    "L2 Cache (per Core):\t256 KB<br>\n",
    "L3 Cache:\t6 MB<br>\n",
    "Memory:\t16 GB<br>\n",
    "Boot ROM Version:\t428.0.0.0.0<br>\n",
    "SMC Version (system):\t2.38f7<br>\n",
    "Serial Number (system):\tC02SXDLLGTFL<br>\n",
    "Hardware UUID:\t52FC23EF-766A-5A25-82B8-8D0614E96355<br>\n",
    "\n",
    "<br></font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The multiprocessing modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<font color=black><br>\n",
    "\n",
    "- Multiprocessing allows your script to do lots of things at once by actually running multiple copies of your script in parallel\n",
    "- One of these copies is known as the **master copy**, and is the one that is used to control all of worker copies.\n",
    "- For this reason it is not recommended to use via ipython!\n",
    "- It forces you to write it in a particular way. All imports should be at the top of the script, followed by all function and class definitions. This is to ensure that all copies of the script have access to the same modules, functions and classes.\n",
    "- Then, you should ensure that only the master copy of the script runs the code by protecting it behind an if **__name__ == \"__main__\"** statement.\n",
    "- The multiprocessing.Pool provides an excellent mechanism for the parallelisation of map/reduce style calculations.\n",
    "\n",
    "<br></font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to run multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<font color=black><br>\n",
    "\n",
    "- Create a new script called **pool.py** and type into it.\n",
    "\n",
    "<br></font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiprocessing.ipynb pool.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from multiprocessing import Pool, cpu_count, current_process\n",
    "\n",
    "def square(x):\n",
    "    \"\"\"Function to return the square of the argument\"\"\"\n",
    "    #print(\"Worker %s calculating square of %s\" % (current_process().pid, x))\n",
    "    return x * x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    You must now protect the code being run by\n",
    "    the master copy of the script by placing it\n",
    "    in this block\n",
    "    \"\"\"\n",
    "    \n",
    "    # print the number of cores\n",
    "    print(\"Number of cores available equals %s\" % cpu_count())\n",
    "    \n",
    "    # create a pool of workers\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    with Pool(processes = cpu_count()) as pool:\n",
    "        # create an array of 5000 integers, from 1 to 5000\n",
    "        r = range(1, 5001)\n",
    "\n",
    "        result = pool.map(square, r)\n",
    "\n",
    "    total = reduce(lambda x, y: x + y, result)\n",
    "\n",
    "    print(\"The sum of the square of the first 5000 integers is %s\" % total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<font color=black><br>\n",
    "\n",
    "- Run the script using the command\n",
    "- The \"!\" allows you to run a commnad as if you were doing it from python sheel direcly\n",
    "- We are forced to do it because it is not advisable to run multiprocessing form ipython\n",
    "\n",
    "<br></font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cores available equals 8\n",
      "The sum of the square of the first 5000 integers is 41679167500\n"
     ]
    }
   ],
   "source": [
    "!python pool.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synchronous function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<font color=black><br>\n",
    "\n",
    "- The Pool.map function allows you to map a single function across an entire list of data. \n",
    "- But what if you want to apply lots of different functions? \n",
    "- To do this you need to use **apply()**\n",
    "- Let's create a script called poolapply.py and type into it\n",
    "\n",
    "<br></font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Pool, current_process\n",
    "\n",
    "def slow_function(nsecs):\n",
    "    \"\"\"\n",
    "    Function that sleeps for 'nsecs' seconds, returning\n",
    "    the number of seconds that it slept\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Process %s going to sleep for %s second(s)\" % (current_process().pid, nsecs))\n",
    "\n",
    "    # use the time.sleep function to sleep for nsecs seconds\n",
    "    time.sleep(nsecs)\n",
    "\n",
    "    print(\"Process %s waking up\" % current_process().pid)\n",
    "\n",
    "    return nsecs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Master process is PID %s\" % current_process().pid)\n",
    "\n",
    "    with Pool() as pool:\n",
    "        r = pool.apply(slow_function, [5])\n",
    "\n",
    "    print(\"Result is %s\" % r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master process is PID 42168\n",
      "Process 42169 going to sleep for 5 second(s)\n",
      "Process 42169 waking up\n",
      "Result is 5\n"
     ]
    }
   ],
   "source": [
    "!python poolapply.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asynchronous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<font color=black><br>\n",
    "\n",
    "- A major problem of Pool.apply is that the master process is blocked until the worker has finished processing the applied function.\n",
    "- **apply_async()** is an asynchronous version of apply that applies the function in a worker process, but without blocking the master.\n",
    "- Let's create a new script called **applyasync.py** and copy into it\n",
    "\n",
    "<br></font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Pool, current_process\n",
    "\n",
    "def slow_add(nsecs, x, y):\n",
    "    \"\"\"\n",
    "    Function that sleeps for 'nsecs' seconds, and\n",
    "    then returns the sum of x and y\n",
    "    \"\"\"\n",
    "    print(\"Process %s going to sleep for %s second(s)\" % (current_process().pid,nsecs))\n",
    "\n",
    "    time.sleep(nsecs)\n",
    "\n",
    "    print(\"Process %s waking up\" % current_process().pid)\n",
    "\n",
    "    return x + y\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Master process is PID %s\" % current_process().pid)\n",
    "\n",
    "    with Pool() as pool:\n",
    "        \"\"\"\n",
    "        The apply_async function is identical to apply, except that it returns control \n",
    "        to the master process immediately. This means that the master process is free to\n",
    "        continue working (e.g. here, it apply_asyncs a second slow_add function). In this\n",
    "        case, it allows us to run two slow_sums in parallel. \n",
    "        \"\"\"\n",
    "        r1 = pool.apply_async(slow_add, [1, 6, 7])\n",
    "        r2 = pool.apply_async(slow_add, [1, 2, 3])\n",
    "\n",
    "        \"\"\"\n",
    "        The master process is then blocked using wait() to wait \n",
    "        for the result of the first and the second call\n",
    "        \"\"\"\n",
    "        r1.wait()\n",
    "        print(\"Result one is %s\" % r1.get())\n",
    "\n",
    "        r2.wait()\n",
    "        print(\"Result two is %s\" % r2.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiprocessing.ipynb pool.py\r\n",
      "applyasync.py         poolapply.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master process is PID 42930\n",
      "Process 42931 going to sleep for 1 second(s)\n",
      "Process 42932 going to sleep for 1 second(s)\n",
      "Process 42931 waking up\n",
      "Process 42932 waking up\n",
      "Result one is 13\n",
      "Result two is 5\n"
     ]
    }
   ],
   "source": [
    "# Remember we cannot run it directly from ipython but have to run it directly in the cmd line\n",
    "!python applyasync.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<font color=black><br>\n",
    "\n",
    "- An issue with running a function asynchronously is that the return value of the function **is not** available immediately. \n",
    "- This means that, when running an asynchronous function, you don't get the return value directly. \n",
    "- Instead, apply_async returns a placeholder for the return value. \n",
    "- This placeholder is called a **future**, and is a variable that in the future will be given the result of the function.\n",
    "- We can explore this more using the script **future.py**\n",
    "\n",
    "<br></font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def slow_add(nsecs, x, y):\n",
    "    \"\"\"\n",
    "    Function that sleeps for 'nsecs' seconds, and\n",
    "    then returns the sum of x and y\n",
    "    \"\"\"\n",
    "    time.sleep(nsecs)\n",
    "    return x + y\n",
    "\n",
    "def slow_diff(nsecs, x, y):\n",
    "    \"\"\"\n",
    "    Function that sleeps for 'nsecs' seconds, and\n",
    "    then retruns the difference of x and y\n",
    "    \"\"\"\n",
    "    time.sleep(nsecs)\n",
    "    return x - y\n",
    "\n",
    "def broken_function(nsecs):\n",
    "    \"\"\"Function that deliberately raises an AssertationError\"\"\"\n",
    "    time.sleep(nsecs)\n",
    "    raise ValueError(\"Called broken function\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    futures = []\n",
    "\n",
    "    with Pool() as pool:\n",
    "        futures.append(pool.apply_async(slow_add, [3, 6, 7]))\n",
    "        futures.append(pool.apply_async(slow_diff, [2, 5, 2]))\n",
    "        futures.append(pool.apply_async(slow_add, [1, 8, 1]))\n",
    "        futures.append(pool.apply_async(slow_diff, [5, 9, 2]))\n",
    "        futures.append(pool.apply_async(broken_function, [4]))\n",
    "\n",
    "        while True:\n",
    "            all_finished = True\n",
    "\n",
    "            print(\"\\nHave the workers finished?\")\n",
    "\n",
    "            for i, future in enumerate(futures):\n",
    "                if future.ready():\n",
    "                    print(\"Process %s has finished\" % i)\n",
    "                else:\n",
    "                    all_finished = False\n",
    "                    print(\"Process %s is running...\" % i)\n",
    "\n",
    "            if all_finished:\n",
    "                break\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "        print(\"\\nHere are the results.\")\n",
    "\n",
    "        for i, future in enumerate(futures):\n",
    "            if future.successful():\n",
    "                print(\"Process %s was successful. Result is %s\" % (i, future.get()))\n",
    "            else:\n",
    "                print(\"Process %s failed!\" % i)\n",
    "\n",
    "                try:\n",
    "                    future.get()\n",
    "                except Exception as e:\n",
    "                    print(\"    Error = %s : %s\" % (type(e), e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiprocessing.ipynb future.py             poolapply.py\r\n",
      "applyasync.py         pool.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Have the workers finished?\n",
      "Process 0 is running...\n",
      "Process 1 is running...\n",
      "Process 2 is running...\n",
      "Process 3 is running...\n",
      "Process 4 is running...\n",
      "\n",
      "Have the workers finished?\n",
      "Process 0 is running...\n",
      "Process 1 is running...\n",
      "Process 2 is running...\n",
      "Process 3 is running...\n",
      "Process 4 is running...\n",
      "\n",
      "Have the workers finished?\n",
      "Process 0 is running...\n",
      "Process 1 has finished\n",
      "Process 2 has finished\n",
      "Process 3 is running...\n",
      "Process 4 is running...\n",
      "\n",
      "Have the workers finished?\n",
      "Process 0 has finished\n",
      "Process 1 has finished\n",
      "Process 2 has finished\n",
      "Process 3 is running...\n",
      "Process 4 is running...\n",
      "\n",
      "Have the workers finished?\n",
      "Process 0 has finished\n",
      "Process 1 has finished\n",
      "Process 2 has finished\n",
      "Process 3 is running...\n",
      "Process 4 has finished\n",
      "\n",
      "Have the workers finished?\n",
      "Process 0 has finished\n",
      "Process 1 has finished\n",
      "Process 2 has finished\n",
      "Process 3 has finished\n",
      "Process 4 has finished\n",
      "\n",
      "Here are the results.\n",
      "Process 0 was successful. Result is 13\n",
      "Process 1 was successful. Result is 3\n",
      "Process 2 was successful. Result is 9\n",
      "Process 3 was successful. Result is 7\n",
      "Process 4 failed!\n",
      "    Error = <class 'ValueError'> : Called broken function\n"
     ]
    }
   ],
   "source": [
    "!python future.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<font color=black><br>\n",
    "\n",
    "- Note that the exception raised by broken_function is held safely in its associated future. \n",
    "- This is indicated by .successful() returning False, thereby allowing us to handle the exception in a try...except block that is put around the .get() function (if you .get() a future that contains an exception, then that exception is raised).\n",
    "\n",
    "<br></font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asynchronous Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<font color=black><br>\n",
    "\n",
    "- Asynchronous functions allow you to give different tasks to different members of the multiprocessing.Pool. \n",
    "- However, giving functions one by one is not very efficient. \n",
    "- It would be good to be able to combine mapping with asynchronous functions, i.e. be able to give different mapping tasks simultanously to the pool of workers. \n",
    "- Fortunately, Pool.map_async provides exactly that - an asynchronous parallel map.\n",
    "- Let's crete a script called **asyncmap.py**\n",
    "\n",
    "<br></font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from multiprocessing import Pool, current_process\n",
    "import time\n",
    "\n",
    "def add(x, y):\n",
    "    \"\"\"Return the sum of the arguments\"\"\"\n",
    "    print(\"Worker %s is processing add(%s, %s)\" % (current_process().pid, x, y))\n",
    "    time.sleep(1)\n",
    "    return x + y\n",
    "\n",
    "def product(x, y):\n",
    "    \"\"\"Return the product of the arguments\"\"\"\n",
    "    print(\"Worker %s is processing product(%s, %s)\" % (current_process().pid, x, y))\n",
    "    time.sleep(1)\n",
    "    return x * y\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    b = [11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "\n",
    "    # Now create a Pool of workers\n",
    "    with Pool() as pool:\n",
    "        sum_future = pool.starmap_async(add, zip(a,b), chunksize = 5)\n",
    "        product_future = pool.starmap_async(product, zip(a,b))\n",
    "\n",
    "        sum_future.wait()\n",
    "        product_future.wait()\n",
    "\n",
    "    total_sum = reduce(lambda x, y: x + y, sum_future.get())\n",
    "    total_product = reduce(lambda x, y: x + y, product_future.get())\n",
    "\n",
    "    print(\"Sum of sums of 'a' and 'b' is %s\" % total_sum)\n",
    "    print(\"Sum of products of 'a' and 'b' is %s\" % total_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiprocessing.ipynb asyncamp.py           pool.py\r\n",
      "applyasync.py         future.py             poolapply.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 44117 is processing add(1, 11)\n",
      "Worker 44118 is processing add(6, 16)\n",
      "Worker 44119 is processing product(1, 11)\n",
      "Worker 44120 is processing product(2, 12)\n",
      "Worker 44121 is processing product(3, 13)\n",
      "Worker 44122 is processing product(4, 14)\n",
      "Worker 44123 is processing product(5, 15)\n",
      "Worker 44124 is processing product(6, 16)\n",
      "Worker 44117 is processing add(2, 12)\n",
      "Worker 44118 is processing add(7, 17)\n",
      "Worker 44119 is processing product(7, 17)\n",
      "Worker 44120 is processing product(8, 18)\n",
      "Worker 44121 is processing product(9, 19)\n",
      "Worker 44122 is processing product(10, 20)\n",
      "Worker 44117 is processing add(3, 13)\n",
      "Worker 44118 is processing add(8, 18)\n",
      "Worker 44118 is processing add(9, 19)\n",
      "Worker 44117 is processing add(4, 14)\n",
      "Worker 44118 is processing add(10, 20)\n",
      "Worker 44117 is processing add(5, 15)\n",
      "Sum of sums of 'a' and 'b' is 210\n",
      "Sum of products of 'a' and 'b' is 935\n"
     ]
    }
   ],
   "source": [
    "!python asyncmap.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<font color=black><br>\n",
    "\n",
    "- Giving work one by one can be very inefficient for quick tasks, as the time needed by a worker process to stop and get new work can be longer than it takes to actually complete the task. \n",
    "- To solve this problem, you can control how many work items are handed out to each worker process at a time. \n",
    "- This is known as chunking, and the number of work items is known as the chunk of work to perform.\n",
    "- **ATTENTION**: using chunksize would suggest to pool that each worker be given a chunk of five pieces of work. Note that this is just a suggestion, and pool may decide to use a slightly smaller or larger chunk size depending on the amount of work and the number of workers available.\n",
    "\n",
    "<br></font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<font color=black><br>\n",
    "\n",
    "- TBC\n",
    "\n",
    "<br></font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font color=black>\n",
    "\n",
    "- https://github.com/chryswoods/siremol.org/blob/master/chryswoods.com/parallel_python/multiprocessing.md<br>\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
